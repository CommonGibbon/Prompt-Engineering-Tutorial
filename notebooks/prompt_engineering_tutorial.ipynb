{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a488e7",
   "metadata": {},
   "source": [
    "**Prompt Optimization & Experiment Tracking with MLflow**\n",
    "\n",
    "This tutorial demonstrates how to optimize prompts and track experiments using MLflow through a practical example.\n",
    "The Task: Finding Melvin\n",
    "\n",
    "We'll train an AI to identify Melvin, a specific cat, from various cat photos. The AI must:\n",
    "\n",
    "    ✅ Accept images containing Melvin\n",
    "    ❌ Reject images without Melvin\n",
    "\n",
    "While humans find this task trivial, AI systems struggle because they lack our common knowledge assumptions about visual recognition.\n",
    "Why Use MLflow?\n",
    "\n",
    "Traditional approaches (classical computer vision, machine learning) would require significant time and resources. Using AI is more efficient, but prompt optimization requires systematic experimentation.\n",
    "\n",
    "MLflow helps us track what works by recording inputs and ouputs for each experiment and providing a convenient UI for results analysis. \n",
    "\n",
    "How MLflow Works\n",
    "\n",
    "    Set storage location - Local folder or cloud storage\n",
    "    Define tracking parameters - Choose what to monitor\n",
    "    Run experiments - MLflow creates subfolders for each run\n",
    "    View results - Launch GUI with poetry run mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e069505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and system configuration\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "\n",
    "from prompt_engineering.utils import CatIdentifier, evaluate_and_plot # custom code written for this experiment. \n",
    "\n",
    "image_path = Path(\"../data/images/\") # images are stored locally for this experiment\n",
    "cat_identifier = CatIdentifier(\"openai/gpt-5-mini\") # initialize and instance of our cat identifier using a decent multi-modal model\n",
    "label_df = pd.read_csv(\"../data/labels.csv\") # manualy generated (by me) labels are stored locally\n",
    "\n",
    "mlflow.set_tracking_uri(\"../mlruns\") # this determines where our ml run data is stored. We're using a local folder here.\n",
    "mlflow.set_experiment(\"cat_id_prompt_optimization\") # set an experiment name to anything descriptive and appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2999be6",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a0165",
   "metadata": {},
   "source": [
    "## System Prompt V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d54e8",
   "metadata": {},
   "source": [
    "For the first pass, lets use a simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_v1 = \"\"\"\n",
    "    Your user owns a tabby cat named Melvin. Your job is to identify whether the image provided is of Melvin, or some other cat.\n",
    "    Respond with your decision, confidence, and reasoning.\n",
    "    \"\"\"\n",
    "\n",
    "prompt_description_v1 = \"\"\"\n",
    "    Baseline\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f8edd8",
   "metadata": {},
   "source": [
    "This prompt is certain to fail. All it tells us is that the cat is a tabby, which represents the mojority of the domesticated cat population. We clearly need to do better but lets use this as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name = \"Baseline performance (notebook)\"): # start_run tells mlflow that we're about to conduct a new experiment. We can name this experiment.\n",
    "    mlflow.log_param(\"prompt_version\", \"v1\") # log that our \"prompt version\" is  \"v1\" \n",
    "    mlflow.log_param(\"prompt_description\", prompt_description_v1) # optionally log a description of the prompt.\n",
    "\n",
    "    # for each cat image, generate a prediction from the AI\n",
    "    results= {image_id: cat_identifier.identify(f\"{image_path}/{image_id}.jpg\", system_prompt_v1) for image_id in label_df.image_id[:2]}\n",
    "    preds = {k:v[\"cat\"] for k,v in results.items()}\n",
    "\n",
    "    acc = evaluate_and_plot(preds, label_df, image_path) # evaluate the predictions against the labels\n",
    "\n",
    "    mlflow.log_metric(\"Accuracy\", acc) # log the accuracy using mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c03ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results) # take a look at the reasoning given for each prediciton - this can help us tune future prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd74c6",
   "metadata": {},
   "source": [
    "## System Prompt V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59a7a85",
   "metadata": {},
   "source": [
    "Our previous prompt described only that Melvin is a tabby, which is not enough to distinguish him from other tabby cats. We need to provide more details to help the model identify the specific cat we are referring to. Lets try and improve our verbal description. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c70305",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_v2 = f\"\"\"\n",
    "    Your user owns a tabby cat named Melvin. Your job is to identify whether the image provided is of Melvin, or some other cat.\n",
    "    Use the following description of Melvin to help you make your decision:\n",
    "    Melvin:\n",
    "        1. Bicolor tabby coat with white underside — Distinctive contrast of dark brown/gray mackerel tabby striping on the back and flanks paired with a large, solid white chest and belly; location: back/sides (tabby), chest/underside (white).\n",
    "\n",
    "        2. Narrow white blaze up the center of the face — A thin vertical white stripe running from the upper muzzle between the eyes toward the forehead, bordered by darker tabby patches on either side; location: center of the face (muzzle to forehead).\n",
    "\n",
    "        3. Pink nose centered in a white muzzle — Prominent pink nose set into a clean white whisker pad and chin area, creating a clear facial focal point; location: nose and lower face/muzzle.\n",
    "       \n",
    "        4. Large round light green eyes with dark rims — Bold, widely set round eyes of light green color framed by darker tabby markings that accentuate their shape; location: eyes/eye rims.\n",
    "\n",
    "        5. Ringed dark tail and white paws — Tail appears uniformly dark with subtle ringed banding toward the base and all four paws predominantly white; location: tail and feet.\n",
    "\n",
    "    When making your descision, consider whether the location of a described feature is visible but that feature is clearly absent. \n",
    "    If you aren't certain, or any feature is missing, respond with \"other\".\n",
    "    Respond with your decision, confidence, and reasoning.\n",
    "    \"\"\"\n",
    "prompt_description_v2 = \"\"\"\n",
    "    A feature-based description of Melvin is used to help the AI make a distinction. \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is the same as before, but we've updated to use the new v2 prompt\n",
    "with mlflow.start_run(run_name = \"Distinctive description (notebook)\"):\n",
    "    mlflow.log_param(\"prompt_version\", \"v2\")\n",
    "    mlflow.log_param(\"promt_description\", prompt_description_v2)\n",
    "\n",
    "    results = {image_id: cat_identifier.identify(f\"{image_path}/{image_id}.jpg\", system_prompt_v2) for image_id in label_df.image_id}\n",
    "    preds = {k:v[\"cat\"] for k,v in results.items()}\n",
    "\n",
    "    acc = evaluate_and_plot(preds, label_df, image_path)\n",
    "\n",
    "    mlflow.log_metric(\"Accuracy\", acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60d306",
   "metadata": {},
   "source": [
    "## System Prompt V3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a0079c",
   "metadata": {},
   "source": [
    "The v2 prompt is already quite good, but if you run it repeatedly, you'll see that it can flip-flop and make mistakes. We can improve it by instructing the AI to follow a chain-of-thought review process and to recursively reconsider its conclusions.\n",
    "This is kind of like spelling out to the AI how it should think, a skill we usually take for granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ce10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_v3 = f\"\"\"\n",
    "    Your user owns a tabby cat named Melvin. Your job is to identify whether the image provided is of Melvin, or some other cat.\n",
    "    Step 1: Feature Analysis\n",
    "    For each image, systematically check if their distinctive features are present.\n",
    "\n",
    "    Melvin Features:\n",
    "        1. Bicolor tabby coat with white underside — Distinctive contrast of dark brown/gray mackerel tabby striping on the back and flanks paired with a large, solid white chest and belly; location: back/sides (tabby), chest/underside (white).\n",
    "\n",
    "        2. Narrow white blaze up the center of the face — A thin vertical white stripe running from the upper muzzle between the eyes toward the forehead, bordered by darker tabby patches on either side; location: center of the face (muzzle to forehead).\n",
    "\n",
    "        3. Pink nose centered in a white muzzle — Prominent pink nose set into a clean white whisker pad and chin area, creating a clear facial focal point; location: nose and lower face/muzzle.\n",
    "\n",
    "        4. Large round light green eyes with dark rims — Bold, widely set round eyes of light green color framed by darker tabby markings that accentuate their shape; location: eyes/eye rims.\n",
    "\n",
    "        5. Ringed dark tail and white paws — Tail appears uniformly dark with subtle ringed banding toward the base and all four paws predominantly white; location: tail and feet.\n",
    "    \n",
    "    Step 2: For each feature, answer the following questions:\n",
    "        a) Is the feature clearly and unambiguously present? (yes/no)\n",
    "        b) If you were to describe the pictured cat, would you use the same language as in the provided description of Melvin?\n",
    "        c) What is my confidence level that the pictured cat is an obvious match for the described feature\n",
    "\n",
    "    Step 3: Consider the possibility that this cat is not Melvin. Does that explain the observations you made during feature analysis? \n",
    "    Re-examine your responses and your confidence levels from step 2. \n",
    "        \n",
    "    Step 4: Final answer with confidence and reasoning. If you aren't certain, or any feature is missing, respond with \"other\". \n",
    "    \"\"\"\n",
    "prompt_description_v3 = \"\"\"\n",
    "    AI prompt enhanced with chain of thought reasoning and recursion instructions.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name = \"Reasoning-enhanced prompt (notebook)\"):\n",
    "    mlflow.log_param(\"prompt_version\", \"v3\")\n",
    "    mlflow.log_param(\"run_description\", prompt_description_v3)\n",
    "\n",
    "    results = {image_id: cat_identifier.identify(f\"{image_path}/{image_id}.jpg\", system_prompt_v3) for image_id in label_df.image_id}\n",
    "    preds = {k:v[\"cat\"] for k,v in results.items()}\n",
    "\n",
    "    acc = evaluate_and_plot(preds, label_df, image_path)\n",
    "\n",
    "    mlflow.log_metric(\"Accuracy\", acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c0560",
   "metadata": {},
   "source": [
    "## System prompt v4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c685c13",
   "metadata": {},
   "source": [
    "All this time, we've been attempting to optimize a prompt by manipulating the text we provide to the model, but this is an inefficient medium for a model which can process images just as easily as text. The smarter approach is therefore to provide a sample image of Melvin alongside the test image to the model can compare across the same modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719996cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_v4 = f\"\"\"\n",
    "    Your user owns a tabby cat named Melvin. They will provide you with two images, a sample image of Melvin, and a test image. Your job is to determine whether the \n",
    "    test image is also Melvin, or some other cat.\n",
    "    \"\"\"\n",
    "prompt_description_v4 = \"\"\"\n",
    "    Prompt with sample image \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name = \"Sample image (notebook)\"):\n",
    "    mlflow.log_param(\"prompt_version\", \"v4\")\n",
    "    mlflow.log_param(\"run_description\", prompt_description_v4)\n",
    "\n",
    "    # DIFFERENCE: note the use of a identify_comp rather than identify. Identify comp takes a path to a sample image as well as a path to a test image.\n",
    "    results = {image_id: cat_identifier.identify_comp(\"../data/sample_images/sample.jpg\", f\"{image_path}/{image_id}.jpg\", system_prompt_v4) for image_id in label_df.image_id}\n",
    "    preds = {k:v[\"cat\"] for k,v in results.items()}\n",
    "\n",
    "    acc = evaluate_and_plot(preds, label_df, image_path)\n",
    "\n",
    "    mlflow.log_metric(\"Accuracy\", acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7743a5",
   "metadata": {},
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ea29a",
   "metadata": {},
   "source": [
    "To review the experiment results, you can run 'mlflow ui' from the terminal (or 'poetry run mlflow ui' in our case). This will give you a web-based UI to explore the results of the experiments we've conducted above.\n",
    "\n",
    "This notebook was meant to walk you through the basics of prompt engineering using MLflow. I highly recommend you take a look a the parallel path of using hydra for configuration management alongside MLflow. Hydra lets you consolodate your configuration changes to a few yaml files, making switching between configurations and tracking changes easy and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9244936",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptengineering-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
